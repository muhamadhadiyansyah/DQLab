# -*- coding: utf-8 -*-
"""Data Manipulation with Pandas - Part 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dY5jCuzJ8tKyqDs85-qwdrgQtCFKLCfa

# Append
"""

import pandas as pd
# Buatlah series of int (s1) dan series of string (s2)
s1 = pd.Series([1, 2, 3, 4, 5, 6])
s2 = pd.Series(["a", "b", "c", "d", "e", "f"])

# Terapkan metode append
s1_append_s2 = s1.append(s2)
print("Series - append:\n", s1_append_s2)

# Buat dataframe df1 dan df2
df1 = pd.DataFrame({'a':[1, 2],
                    'b':[3, 4]})
df2 = pd.DataFrame({'b':[1, 2],
                    'a':[3, 4]})
# Terapkan method append
df2_append_df1 = df2.append(df1)
print("Dataframe - append:\n", df2_append_df1)

"""# Concat"""

import pandas as pd

# Buat dataframe df1 dan df2
df1 = pd.DataFrame({'a':[1, 2],
                    'b':[3, 4]})
df2 = pd.DataFrame({'b':[1, 2],
                    'a':[3, 4]})

# Terapkan method concat row-wise
row_wise_concat = pd.concat([df2, df1])
print("Row-wise - concat:\n", row_wise_concat)

# Terapkan method concat column-wise
col_wise_concat = pd.concat([df2, df1], axis=1)
print("Column-wise - concat:\n", col_wise_concat)

# Penambahan identifier --> membentuk hasil penggabungan multiindex
multiindex_concat = pd.concat([df2, df1], axis=0, keys=['df1', 'df2'])
print("Multiindex - concat:\n", multiindex_concat)

"""# Merge - Part 1"""

import pandas as pd
# Buat dataframe df1 dan df2
df1 = pd.DataFrame({'key':['k1', 'k2', 'k3', 'k4', 'k5'],
                    'val1':[200, 500, 0, 500, 100],
                    'val2':[30, 50, 100, 20, 10]})
df2 = pd.DataFrame({'key':['k1', 'k3', 'k5', 'k7', 'k10'],
                    'val3':[1, 2, 3, 4, 5],
                    'val4':[6, 7, 8, 8, 10]})

# Merge yang ekivalen dengan SQL left join
merge_df_left = pd.merge(left=df2, right=df1, how='left', left_on='key', right_on='key')
print('Merge - Left:\n', merge_df_left)

# Merge yang ekivalen dengan SQL right join
merge_df_right = pd.merge(left=df2, right=df1, how='right', left_on='key', right_on='key')
print('Merge - Right:\n', merge_df_right)

# Merge yang ekivalen dengan SQL inner join
merge_df_inner = pd.merge(left=df2, right=df1, how='inner', left_on='key', right_on='key')
print('Merge - Inner:\n', merge_df_inner)

# Merge yang ekivalen dengan SQL outer join
merge_df_outer = pd.merge(left=df2, right=df1, how='outer', left_on='key', right_on='key')
print('Merge - Outer:\n', merge_df_outer)

"""# Merge - Part 2"""

import pandas as pd

# Buat dataframe df1 dan df2
df1 = pd.DataFrame({'key':['k1', 'k2', 'k3', 'k4', 'k5'],
                    'val1':[200, 500, 0, 500, 100], 
                    'val2':[30, 50, 100, 20, 10]}).set_index(['key', 'val2'])
print('Dataframe 1:\n', df1)

df2 = pd.DataFrame({'key':['k1', 'k3', 'k5', 'k7', 'k10'],
                    'val3':[1, 2, 3, 4, 5], 
                    'val4':[6, 7, 8, 8, 10]}).set_index(['key', 'val3'])
print('Dataframe 2:\n', df2)

# Merge dataframe yang memiliki multi index
df_merge = pd.merge(df1.reset_index(), df2.reset_index())
print('Merging dataframe:\n', df_merge)

"""# Join"""

import pandas as pd

# Buat dataframe df1 dan df2
df1 = pd.DataFrame({'key':['k1', 'k2', 'k3', 'k4', 'k5'],
                    'val1':[200, 500, 0, 500, 100],
                    'val2':[30, 50, 100, 20, 10]})
df2 = pd.DataFrame({'key':['k1', 'k3', 'k5', 'k7', 'k10'],
                    'val3':[1, 2, 3, 4, 5],
                    'val4':[6, 7, 8, 8, 10]})

# Penerapan join dengan menggunakan set_index dan keyword how
join_df = df1.set_index('key').join(df2.set_index('key'), how='outer')
print(join_df)

"""# Dataset"""

import pandas as pd
# Dataframe
data = pd.DataFrame({'kelas': 6 * ['A'] + 6 * ['B'],
                     'murid': 2 * ['A1'] + 2 * ['A2'] + 2 * ['A3'] + 2 * ['B1'] + 2 * ['B2'] + 2 * ['B3'],
                     'pelajaran': 6 * ['math','english'],
                     'nilai': [90, 60, 70, 85, 50, 60, 100, 40, 95, 80, 60, 45]}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])

# Unique value pada setiap kolom data
for column in data.columns:
    print('Unique value %s: %s' % (column, data[column].unique()))

"""# Pivot"""

import pandas as pd
# Dataframe
data = pd.DataFrame({'kelas': 6 * ['A'] + 6 * ['B'],
                     'murid': 2 * ['A1'] + 2 * ['A2'] + 2 * ['A3'] + 2 * ['B1'] + 2 * ['B2'] + 2 * ['B3'],
                     'pelajaran': 6 * ['math', 'english'],
                     'nilai': [90, 60, 70, 85, 50, 60, 100, 40, 95, 80, 60, 45]}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])

# Pivoting with single column measurement
pivot1 = data.pivot(index='murid', columns='pelajaran', values='nilai')
print('Pivoting with single column measurement:\n', pivot1)

# Pivoting with multiple column measurement
pivot2 = data.pivot(index='murid', columns='pelajaran')
print('Pivoting with multiple column measurement:\n', pivot2)

"""# Pivot_table"""

import pandas as pd
# Dataframe
data = pd.DataFrame({'kelas': 6 * ['A'] + 6 * ['B'],
                     'murid': 2 * ['A1'] + 2 * ['A2'] + 2 * ['A3'] + 2 * ['B1'] + 2 * ['B2'] + 2 * ['B3'],
                     'pelajaran': 6 * ['math', 'english'],
                     'nilai': [90, 60, 70, 85, 50, 60, 100, 40, 95, 80, 60, 45]}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])

# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='mean'
pivot_tab_mean = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean')
print('Creating pivot table -- aggfunc mean:\n', pivot_tab_mean)

# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='median'
pivot_tab_median = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='median')
print('Creating pivot table -- aggfunc median:\n', pivot_tab_median)

# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc=sum
pivot_tab_sum = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc=sum)
print('Creating pivot table -- aggfunc sum:\n', pivot_tab_sum)

"""# Melt - Part 1"""

import pandas as pd
# Dataframe
data = pd.DataFrame({'kelas': 6 * ['A'] + 6 * ['B'],
                     'murid': 2 * ['A1'] + 2 * ['A2'] + 2 * ['A3'] + 2 * ['B1'] + 2 * ['B2'] + 2 * ['B3'],
                     'pelajaran': 6 * ['math', 'english'],
                     'nilai': [90, 60, 70, 85, 50, 60, 100, 40, 95, 80, 60, 45]}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])

# Pivoting dataframe
data_pivot = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean').reset_index()
print('Pivoting dataframe:\n', data_pivot)

# [1] Melting dataframe data_pivot
data_melt_1 = pd.melt(data_pivot)
print('Melting dataframe:\n', data_melt_1)

# [2] Melting dataframe data_pivot dengan id_vars
data_melt_2 = pd.melt(data_pivot, id_vars='kelas')
print('Melting dataframe dengan idvars:\n', data_melt_2)

"""# Melt - Part 2"""

import pandas as pd
# Dataframe
data = pd.DataFrame({'kelas': 6 * ['A'] + 6 * ['B'],
                     'murid': 2 * ['A1'] + 2 * ['A2'] + 2 * ['A3'] + 2 * ['B1'] + 2 * ['B2'] + 2 * ['B3'],
                     'pelajaran': 6 * ['math', 'english'],
                     'nilai': [90, 60, 70, 85, 50, 60, 100, 40, 95, 80, 60, 45]}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])

# Pivoting dataframe
data_pivot = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean').reset_index()
print('Pivoting dataframe:\n', data_pivot)

# [3.a] Melting dataframe data_pivot dengan value_vars
data_melt_3a = pd.melt(data_pivot, value_vars=['math'])
print('Melting dataframe dengan value_vars:\n', data_melt_3a)

# [3.b] Melting dataframe data_pivot dengan id_vars dan value_vars
data_melt_3b = pd.melt(data_pivot, id_vars='kelas', value_vars=['math'])
print('Melting dataframe dengan id_vars dan value_vars:\n', data_melt_3b)

# [4] Melting dataframe data_pivot dengan id_vars, value_vars, var_name. dan value_name
data_melt_4 = pd.melt(data_pivot, id_vars='kelas', value_vars=['english','math'], var_name='pelajaran', value_name='nilai')
print('Melting dataframe dengan id_vars, value_vars, var_name. dan value_name:\n', data_melt_4)

"""# Stack & Unstack - Part 1"""

import pandas as pd
# Dataframe
data = pd.DataFrame({'kelas': 6 * ['A'] + 6 * ['B'],
                     'murid': 2 * ['A1'] + 2 * ['A2'] + 2 * ['A3'] + 2 * ['B1'] + 2 * ['B2'] + 2 * ['B3'],
                     'pelajaran': 6 * ['math', 'english'],
                     'nilai': [90, 60, 70, 85, 50, 60, 100, 40, 95, 80, 60, 45]}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])

# Set index data untuk kolom kelas, murid, dan pelajaran
data = data.set_index(['kelas', 'murid', 'pelajaran'])
print('Dataframe multi index:\n', data)

# [1] Unstacking dataframe
data_unstack_1 = data.unstack()
print('Unstacking dataframe:\n', data_unstack_1)

# [2] Unstacking dengan specify level name
data_unstack_2 = data.unstack(level='murid')
print('Unstacking dataframe dengan level name:\n', data_unstack_2)

# [3] Unstacking dengan specify level position
data_unstack_3 = data.unstack(level=1)
print('Unstacking dataframe dengan level position:\n', data_unstack_3)

"""# Stack & Unstack - Part 2"""

import pandas as pd
# Dataframe
data = pd.DataFrame({'kelas': 6 * ['A'] + 6 * ['B'],
                     'murid': 2 * ['A1'] + 2 * ['A2'] + 2 * ['A3'] + 2 * ['B1'] + 2 * ['B2'] + 2 * ['B3'],
                     'pelajaran': 6 * ['math', 'english'],
                     'nilai': [90, 60, 70, 85, 50, 60, 100, 40, 95, 80, 60, 45]}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])
data = data.set_index(['kelas', 'murid', 'pelajaran'])
data_unstack = data.unstack(level=1)
print('Dataframe:\n', data_unstack)

# [1] Stacking dataframe
data_stack = data_unstack.stack()
print('Stacked dataframe:\n', data_stack)

# [2] Tukar posisi index setelah stacking dataframe
data_swap = data_stack.swaplevel(1, 2)
print('Swapped data:\n', data_swap)

# [3] Melakukan sort_index pada stacking dataframe
data_sort = data_swap.sort_index()
print('Sorted data:\n', data_sort)

"""# Review Inspeksi Data"""

import pandas as pd
# Load data global_air_quality.csv
global_air_quality = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')
print('Lima data teratas:\n', global_air_quality.head())

# Melakukan pengecekan terhadap data
print('Info global_air_quality:\n', global_air_quality.info())

# Melakukan count tanpa groupby
print('Count tanpa groupby:\n', global_air_quality.count())

# Melakukan count dengan groupby 
gaq_groupby_count = global_air_quality.groupby('source_name').count()
print('Count dengan groupby (5 data teratas):\n', gaq_groupby_count.head())

"""# Groupby dan Aggregasi dengan Fungsi Statistik Dasar - Part 1"""

import pandas as pd
# Load data global_air_quality.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')

# Create variabel pollutant 
pollutant = gaq[['country', 'city', 'pollutant', 'value']].pivot_table(index=['country', 'city'], columns='pollutant').fillna(0)
print('Data pollutant (5 teratas):\n', pollutant.head())

# [1] Group berdasarkan country dan terapkan aggregasi mean
pollutant_mean = pollutant.groupby('country').mean()
print('Rata-rata pollutant (5 teratas):\n', pollutant_mean.head())

# [2] Group berdasarkan country dan terapkan aggregasi std
pollutant_std = pollutant.groupby('country').std().fillna(0)
print('Standar deviasi pollutant (5 teratas):\n', pollutant_std.head())

"""# Groupby dan Aggregasi dengan Fungsi Statistik Dasar - Part 2"""

# [3] Group berdasarkan country dan terapkan aggregasi sum
pollutant_sum = pollutant.groupby('country').sum()
print('Total pollutant (5 teratas):\n', pollutant_sum.head())

# [4] Group berdasarkan country dan terapkan aggregasi nunique
pollutant_nunique = pollutant.groupby('country').nunique()
print('Jumlah unique value pollutant (5 teratas):\n', pollutant_nunique.head())

"""# Groupby dan Aggregasi dengan Fungsi Statistik Dasar - Part 3"""

# Group berdasarkan country dan terapkan aggregasi min
pollutant_min = pollutant.groupby('country').min()
print('Nilai min pollutant (5 teratas):\n', pollutant_min.head())

# Group berdasarkan country dan terapkan aggregasi max
pollutant_max = pollutant.groupby('country').max()
print('Nilai min pollutant (5 teratas):\n', pollutant_max.head())

# Group berdasarkan country dan terapkan aggregasi first
pollutant_first = pollutant.groupby('country').first()
print('Item pertama pollutant (5 teratas):\n', pollutant_first.head())

# Group berdasarkan country dan terapkan aggregasi last
pollutant_last = pollutant.groupby('country').last()
print('Item terakhir pollutant (5 teratas):\n', pollutant_last.head())

"""# Groupby dengan Multiple Aggregations"""

import pandas as pd
# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')

# Create variabel pollutant 
pollutant = gaq[['country', 'city', 'pollutant', 'value']].pivot_table(index=['country', 'city'], columns='pollutant').fillna(0)
print('Data pollutant (5 teratas):\n', pollutant.head())

# Group berdasarkan country dan terapkan aggregasi: min, median, mean, max
multiagg = pollutant.groupby('country').agg(['min', 'median', 'mean', 'max'])
print('Multiple aggregations (5 teratas):\n', multiagg.head())

"""# Groupby dengan Custom Aggregations"""

import pandas as pd
# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')

# Create variabel pollutant 
pollutant = gaq[['country', 'city', 'pollutant', 'value']].pivot_table(index=['country', 'city'], columns='pollutant').fillna(0)
print('Data pollutant (5 teratas):\n', pollutant.head())

# Create function: data_range
def data_range(series):
    return series.max() - series.min()

# Group berdasarkan country dan terapkan aggregasi dari function: range
custom_agg = pollutant.groupby('country').agg(data_range)
print('Custom aggregation (5 teratas):\n', custom_agg.head())

# Create sebuah function: iqr
def iqr(series):
	Q1 = series.quantile(0.25)
	Q3 = series.quantile(0.75)
	return Q3 - Q1

# Group berdasarkan country dan terapkan aggregasi dari function: iqr
custom_agg = pollutant.groupby('country').agg(iqr)
print('Custom aggregation (5 teratas):\n', custom_agg.head())

"""# Groupby dengan Custom Aggregations by dict"""

import pandas as pd
# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')

# Create variabel pollutant 
pollutant = gaq[['country', 'city', 'pollutant', 'value']].pivot_table(index=['country', 'city'], columns='pollutant').fillna(0)
print('Data pollutant (5 teratas):\n', pollutant.head())

# Function IQR
def iqr(series):
	return series.quantile(0.75) - series.quantile(0.25)

# Create custom aggregation using dict
custom_agg_dict = pollutant['value'][['pm10', 'pm25', 'so2']].groupby('country').agg({'pm10':'median',
                                                                                      'pm25':iqr,
                                                                                      'so2':iqr})
print('\nCetak 5 data teratas custom_agg_dict:\n', custom_agg_dict.head())

"""# Load Dataset as Time Series"""

import pandas as pd
# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv', parse_dates=True, index_col='timestamp')
# Cetak 5 data teratas
print(gaq.head())

# Cetak info dari dataframe gaq
print('info')
print(gaq.info())

"""# Convert to Datetime"""

import pandas as pd
# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')
# Cetak 5 data teratas
print('Sebelum diubah dalam format datetime:\n', gaq.head())

# Ubah menjadi datetime
gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])
gaq = gaq.set_index('timestamp')

# Cetak 5 data teratas
print('Sesudah diubah dalam format datetime:\n', gaq.head())

"""# Downsampling Data"""

import pandas as pd
# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')
gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])
gaq = gaq.set_index('timestamp')
print('Dataset sebelum di-downsampling (5 teratas):\n', gaq.head())

# Downsampling dari daily to monthly dan kita hitung rata-rata untuk sebulan
gaq_monthly = gaq.resample('M').mean()
print('Downsampling daily to monthly - mean (5 teratas):\n', gaq_monthly.head())

# Downsampling dari daily to yearly dan kita hitung total untuk setiap tahun
gaq_yearly = gaq.resample('A').sum()
print('Downsampling daily to yearly - sum (5 teratas):\n', gaq_yearly.head())

[1] Downsampling dari daily to weekly dan kita hitung maksimum untuk seminggu
gaq_weekly = gaq.resample('W').max()
print('Downsampling daily to weekly - max (5 teratas):\n', gaq_weekly.head())

# [2] Downsampling dari daily to quaterly dan kita hitung minimumnya untuk tiap quarter
gaq_quaterly = gaq.resample('Q').min()
print('Downsampling daily to quaterly - min (5 teratas):\n', gaq_quaterly.head())

"""# Upsampling Data"""

import pandas as pd
# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')
gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])
gaq = gaq.set_index('timestamp')
print('Dataset sebelum di-upsampling (5 teratas):\n', gaq.head())

# Upsampling dari daily to hourly dan kita hitung reratanya
gaq_hourly = gaq.resample('H').mean()
print('Upsampling daily to hourly - mean (5 teratas):\n', gaq_hourly.head())

"""# Resampling by Frequency"""

import pandas as pd
# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')
gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])
gaq = gaq.set_index('timestamp')
print('Dataset sebelum di-resampling (5 teratas):\n', gaq.head())

# Downsampling dari daily to 2 weekly, hitung reratanya, dan fillna = 'ffill'
gaq_2weekly = gaq.resample('2W').mean().fillna(method='ffill')
print('Resampling daily to 2 weekly - mean - ffill (5 teratas):\n', gaq_2weekly.head())

# Upsampling dari daily to 8 hourly, hitung reratanya, dan fillna = 'bfill'
gaq_8hourly = gaq.resample('8H').mean().fillna(method='bfill')
print('Resampling daily to 8 hourly - mean - bfill (5 teratas):\n', gaq_8hourly.head())

# Resample dari daily to 2 monthly, hitung reratanya, dan fillna = 'bfill'
gaq_2monthly = gaq.resample('2M').mean().fillna(method='bfill')
print('Resampling daily to 2 monthly - mean - bfill (5 teratas):\n', gaq_2monthly.head())

"""# Visualisasi"""

import pandas as pd
import matplotlib.pyplot as plt
# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv
gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')
gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])
gaq = gaq.set_index('timestamp')

# [1] Membuat pivot table yang menunjukkan waktu di baris nya dan masing-masing value dari pollutant nya dalam kolom
gaq_viz = gaq[['pollutant', 'value']].reset_index().set_index(['timestamp', 'pollutant'])
gaq_viz = gaq_viz.pivot_table(index='timestamp', columns='pollutant', aggfunc='mean').fillna(0)
gaq_viz.columns = gaq_viz.columns.droplevel(0)
print('Data (5 teratas):\n', gaq_viz.head())

# [2] Membuat fungsi yang memberikan default value 0 ketika value nya di bawah 0 dan apply ke setiap elemen dari dataset tersebut, kemudian menampilkannya sebagai chart
def default_val(val):
 if val < 0:
   return 0
 else:
   return val
line1 = gaq_viz.resample('M').mean().ffill().applymap(lambda x: default_val(x)).apply(lambda x: x/x.max()) # default value if value < 0 then 0, kemudian menghasilkan % value = value/max(value)
line1.plot(
   title = 'average value of each pollutant over months',
   figsize = (10,10), #ukuran canvas 10px x 10px
   ylim = (0,1.25), #memberikan batas tampilan y-axis hanya 0 sampai 125%
   subplots = True #memecah plot menjadi beberapa bagian sesuai dengan jumlah kolom
)
plt.ylabel('avg pollutant (%)')
plt.xlabel('month')
plt.show()

"""# Performa Penjualan di Setiap Cabang - Part 1"""

import pandas as pd
import matplotlib.pyplot as plt

# [1]. Load masing-masing data dengan pandas
retail_data1 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_1_until_3.csv')
retail_data2 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_4_until_6.csv')
retail_data3 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_7_until_9.csv')
retail_data4 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_10_until_12.csv')

# [2]. Pengecekan Data
print('PENGECEKAN DATA\n\n')

# Cek data sekilas (tampilkan 5 baris teratas)
print(retail_data1.head())

# Cek list kolom untuk semua dataframe
print('Kolom retail_data1: %s' %retail_data1.columns)
print('Kolom retail_data2: %s' %retail_data2.columns)
print('Kolom retail_data3: %s' %retail_data3.columns)
print('Kolom retail_data4: %s' %retail_data4.columns)

# Concat multiple dataframe menjadi 1 dataframe
retail_table = pd.concat([retail_data1, retail_data2, retail_data3, retail_data4])
print('\nJumlah baris:', retail_table.shape[0])

# Pengecekan dataframe info
print('\nInfo:')
print(retail_table.info())

# Pengecekan statistik deskriptif
print('\nStatistik deskriptif:\n', retail_table.describe())

"""# Performa Penjualan di setiap Cabang - Part 2"""

# [3]. Transformasi Data
print('TRANSFORMASI DATA\n\n')

# Memastikan data yang memiliki item_price < 0 atau total_price < 0
cek = retail_table.loc[(retail_table['item_price'] < 0) | (retail_table['total_price'] < 0)]
print('\nitem_price < 0 atau total_price < 0:\n', cek)

# Jika tidak masuk akal datanya dapat dibuang
if cek.shape[0] != 0:
  retail_table = retail_table.loc[(retail_table['item_price'] > 0) & (retail_table['total_price'] > 0)]

# Cek apakah masih ada order_id yang bernilai undefined dan delete row tersebut
cek = retail_table.loc[retail_table['order_id'] == 'undefined']
print('\norder_id yang bernilai undefined:\n', cek)

# Jika ada maka buang baris tersebut
if cek.shape[0] != 0:
	retail_table = retail_table.loc[retail_table['order_id'] != 'undefined']

# Transform order_id menjadi int64
retail_table['order_id'] = retail_table['order_id'].astype('int64')

# Transform order_date menjadi datetime Pandas
retail_table['order_date'] = pd.to_datetime(retail_table['order_date'])

# Cek dataframe info kembali untuk memastikan
print('\nInfo:')
print(retail_table.info())

# Cek statistik deskriptif kembali, untuk memastikan
print('\nStatistik deskriptif:\n', retail_table.describe())

"""# Performa Penjualan di setiap Cabang - Part 3"""

# [4]. Filter hanya 5 province terbesar di pulau Jawa
print('\nFILTER 5 PROVINCE TERBESAR DI PULAU JAWA\n')
java = ['DKI Jakarta', 'Jawa Barat', 'Jawa Tengah', 'Jawa Timur', 'Yogyakarta']
retail_table = retail_table.loc[retail_table['province'].isin(java)]

# Untuk memastikan kolom provinsi isinya sudah sama dengan java
print(retail_table['province'].unique())

# [5]. Kelompokkan sesuai dengan order_date dan province kemudian aggregasikan
groupby_city_province = retail_table.groupby(['order_date', 'province']).agg({
   'order_id': 'nunique',
   'customer_id': 'nunique',
   'product_id': 'nunique',
   'brand': 'nunique',
   'total_price': sum
})

# Ubah nama kolomnya menjadi 'order','customer','product','brand','GMV'
groupby_city_province.columns = ['order', 'customer', 'product', 'brand', 'GMV']
print('\ngroupby_city_province (10 data teratas):\n', groupby_city_province.head(10))

# [6]. Unstack untuk mendapatkan order_date di bagian baris dan province di bagian column
unstack_city_province = groupby_city_province.unstack('province').fillna(0)
print('\nunstack_city_province (5 data teratas):\n', unstack_city_province.head())

"""# Performa Penjualan di setiap Cabang - Part 4"""

# [7]. Slicing data untuk masing-masing measurement, misal: order
idx = pd.IndexSlice
by_order = unstack_city_province.loc[:, idx['order']]
print('\nby order (5 data teratas):\n', by_order.head())

# [8]. Lakukan resampling pada data tersebut untuk dilakukan perhitungan rata-rata bulanan 
by_order_monthly_mean = by_order.resample('M').mean()
print('\nby_order_monthly_mean (5 data teratas):\n', by_order_monthly_mean.head())

"""# Performa Penjualan di setiap Cabang - Part 5"""

import matplotlib.pyplot as plt

# [9]. Plot untuk hasil pada langkah #[8]
by_order_monthly_mean.plot(
   figsize = (8,5),
   title = 'Average Daily order Size in Month View for all Province'
)
plt.ylabel('avg order size')
plt.xlabel('month')
plt.show()

"""# Performa Penjualan di setiap Cabang - Part 6"""

import matplotlib.pyplot as plt

# Create figure canvas dan axes for 5 line plots
fig, axes = plt.subplots(5, 1, figsize=(8, 25))

# Slicing index
idx = pd.IndexSlice
for i, measurement in enumerate(groupby_city_province.columns):
    # Slicing data untuk masing-masing measurement
    by_measurement = unstack_city_province.loc[:, idx[measurement]]
    # Lakukan resampling pada data tersebut untuk dilakukan perhitungan rata-rata bulanan 
    by_measurement_monthly_mean = by_measurement.resample('M').mean()
    # Plot by_measurement_monthly_mean
    by_measurement_monthly_mean.plot(
        title = 'Average Daily ' + measurement + ' Size in Month View for all Province',
        ax = axes[i]
    )
    axes[i].set_ylabel('avg ' + measurement + ' size')
    axes[i].set_xlabel('month')

# Adjust the layout and show the plot
plt.tight_layout()
plt.show()